{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bokutachi256/gisday2025/blob/main/GISDAY2025_Python%E3%81%A8GIS%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AB%E3%82%88%E3%82%8B%E5%9C%B0%E5%BD%A2%E5%88%86%E6%9E%90%E5%85%A5%E9%96%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5RsOreAToG1"
      },
      "source": [
        "# PythonとGISを使った機械学習による地形分析入門"
      ],
      "id": "b5RsOreAToG1"
    },
    {
      "cell_type": "markdown",
      "id": "b11052ce",
      "metadata": {
        "id": "b11052ce"
      },
      "source": [
        "* GIS Day in 東京 2025 Eコース\n",
        "* Python とGISを使った機械学習による地形分析入門\n",
        "* 東京都立大学 都市環境学部 地理環境学科 中山大地（daichi@tmu.ac.jp）\n",
        "* 2025年11月22日 東京都立大学 南大沢キャンパス\n",
        "\n",
        "* github repository: [www.github.com/bokutachi256/gisday2025](https://www.github.com/bokutachi256/gisday2025)\n",
        "* Google ColaboratoryのURL [https://colab.research.google.com/](https://colab.research.google.com/)\n",
        "* 参考になるページ\n",
        "  - [scikit-learn のマニュアルページ](https://gdal.org/python/)\n",
        "  - [平成29年7月九州北部豪雨に関する情報（国土地理院）](https://www.gsi.go.jp/BOUSAI/H29hukuoka_ooita-heavyrain.html)\n",
        "  - [正射画像判読図（朝倉・東峰地区）・GeoJSONファイルのダウンロード（上記ページ）](https://www.gsi.go.jp/BOUSAI/H29hukuoka_ooita-heavyrain.html#9)\n",
        "* 更新履歴\n",
        "  * 2025年11月22日：初版公開\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c52abf8",
      "metadata": {
        "id": "3c52abf8"
      },
      "source": [
        "## はじめに"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5309e88a",
      "metadata": {
        "id": "5309e88a"
      },
      "source": [
        "この講習では，国土地理院が公開している平成29年7月九州北部豪雨時の土砂崩壊ポリゴンと10m解像度DEMから，\n",
        "機械学習の一種である決定木を用いて土砂崩壊地を推定するモデルを作成することを目的としています．\n",
        "手順の概要は以下になります．\n",
        "\n",
        "1. 平成29年7月九州北部豪雨の災害状況ベクタデータを読み込み，土砂崩壊ポリゴンを抽出する．\n",
        "2. あらかじめDEMから計算した地形量ラスタデータを読み込む．\n",
        "3. 対象地域を覆う100mメッシュごとに地形量と土砂崩壊の有無を集計する．\n",
        "4. 100mメッシュごとの地形量を説明変数，土砂崩壊の有無を目的変数とする決定木を作成する．\n",
        "5. 作成した決定木を評価し，チューニングする．\n",
        "6. 作成した決定木に基づく混同行列マップから土砂崩壊ポテンシャルを求めて地図化する．\n",
        "7. 作成した決定木に基づく葉ノードを地図化し，ノードごとの土砂崩壊の状態を考察する．\n",
        "8. メッシュに集計した結果をエクスポートし，GISで使えるようにする．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96f14bd0",
      "metadata": {
        "id": "96f14bd0"
      },
      "source": [
        "## 使い方"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e78921e5",
      "metadata": {
        "id": "e78921e5"
      },
      "source": [
        "### 動作環境について"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db801643",
      "metadata": {
        "id": "db801643"
      },
      "source": [
        "1. Googleドライブに`gisday2025`フォルダを作成する（フォルダ名は「すべて小文字」にすること）．\n",
        "2. 共有フォルダ（[https://drive.google.com/drive/folders/17yH9qPEzIxRaS94WipiH3bKX5r1aCa9Z?usp=sharing](https://drive.google.com/drive/folders/17yH9qPEzIxRaS94WipiH3bKX5r1aCa9Z?usp=sharing)）から以下のデータをダウンロードしてください．\n",
        "   * `20170810asakura_toho_handokuzu.geojson`：国土地理院からダウンロードした平成29年7月九州北部豪雨時の朝倉・東峰地区の正射画像判読データ\n",
        "   * `AOI.geojson`：集計用の100mメッシュポリゴン\n",
        "   * `output_dem_reprojected.tif`：10m 解像度数値標高モデル\n",
        "   * `output_dis.tif`：侵食高\n",
        "   * `output_hillshade.tif`：陰影起伏図\n",
        "   * `output_plc.tif`：平面曲率（PlC）\n",
        "   * `output_prc.tif`：断面曲率（PrC）\n",
        "   * `output_slope_deg.tif`：傾斜量\n",
        "   * `output_stilog.tif`：土砂移動指数（STI）\n",
        "   * `output_wetnessindex.tif`：湿潤指数（WI）\n",
        "3. Google Driveに作成した`gisday2025`フォルダに上記のファイルをアップロードしてください．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "212d5692",
      "metadata": {
        "id": "212d5692"
      },
      "source": [
        "### 実行環境の自動判定"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bb0c0d0",
      "metadata": {
        "id": "7bb0c0d0"
      },
      "source": [
        "このプログラムがgoogle colaboratoryで動いているか，\n",
        "ローカルなPythonで動いているか判別し，\n",
        "GoogleDriveのマウントやベースディレクトリの指定を自動的に行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53fa1a48",
      "metadata": {
        "id": "53fa1a48"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    # 必要なライブラリをインストール\n",
        "    %pip install rasterio\n",
        "    %pip install rasterstats\n",
        "    %pip install geocube\n",
        "    %pip install mapclassify\n",
        "\n",
        "    # GoogleDriveのマウント\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    # GoogleDrive内の\"マイドライブ/gisday2025/\"フォルダにアクセスできるような設定を行う．\n",
        "    # フォルダ名の最後に`/`を必ず追加すること．\n",
        "\n",
        "    # ベースディレクトリの指定\n",
        "    base_dir = \"/content/drive/My Drive/gisday2025/\"\n",
        "\n",
        "else:\n",
        "    # ローカルPCを使う場合は./data/フォルダをマウントする\n",
        "    # フォルダ名の最後に`/`を必ず追加すること．\n",
        "    base_dir = \"./data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35abe7b9",
      "metadata": {
        "id": "35abe7b9"
      },
      "source": [
        "### ライブラリの読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "358c6a64",
      "metadata": {
        "id": "358c6a64"
      },
      "source": [
        "使用するライブラリを説明します．\n",
        "\n",
        "* `numpy`：多次元配列計算のライブラリ\n",
        "* `pandas`: データベース的な処理を行うライブラリ\n",
        "* `geopandas`：地理情報を扱うライブラリ\n",
        "* `folium`：インタラクティブマップを作成するライブラリ\n",
        "* `rasterio`：ラスタ型の空間データを扱うライブラリ\n",
        "* `geocube`：ベクタ型データとラスタ型データを変換するライブラリ\n",
        "* `rasterstats`：ラスタデータの集計（ゾーン集計）を行うライブラリ\n",
        "* `matplotlib`：画像表示ライブラリ\n",
        "* `sklearn`：機械学習用ライブラリ\n",
        "* `google.colab`: Google Colaboratory用ライブラリ．google driveのマウントに使用．\n",
        "\n",
        "以下で使用するライブラリを導入します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f88a6e8e",
      "metadata": {
        "id": "f88a6e8e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import folium\n",
        "import rasterio\n",
        "from geocube.api.core import make_geocube\n",
        "from rasterstats import zonal_stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split, \\\n",
        "    GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree,\\\n",
        "    export_graphviz\n",
        "from sklearn.metrics import accuracy_score, classification_report,\\\n",
        "    confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e562966",
      "metadata": {
        "id": "0e562966"
      },
      "source": [
        "## データの読み込みと確認"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6908c9ac",
      "metadata": {
        "id": "6908c9ac"
      },
      "source": [
        "### 被害状況ベクタデータの読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6844e210",
      "metadata": {
        "id": "6844e210"
      },
      "source": [
        "使用する被害状況ベクタデータ（平成29年7月九州北部豪雨時の朝倉・東峰地区の正射画像判読データ）と\n",
        "集計用の100mメッシュデータのGeoJSONを読み込みます．\n",
        "読み込んだデータはGeoPandasのGeoDataFrame型式になります．\n",
        "読み込んだデータは`to_crs`メソッドを用いて世界測地系（JGD2011）の平面直角座標系（公共測量座標系）第Ⅱ系（epsg6670）に投影変換します．\n",
        "読み込んだ被害状況ベクタデータは`ls_polygon`，\n",
        "メッシュデータは`aoi_polygon`とします．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fac000d2",
      "metadata": {
        "id": "fac000d2"
      },
      "outputs": [],
      "source": [
        "# 被害状況ベクタデータのGeoJSONを読み込み，\n",
        "# epsg6670（JGD2011平面直角座標系第2系）に変換する\n",
        "\n",
        "ls_polygon = gpd.read_file(base_dir + \"20170810asakura_toho_handokuzu.geojson\")\\\n",
        "    .to_crs(epsg=6670)\n",
        "\n",
        "# 分析対象のメッシュを読み込み，epsg6670に変換する\n",
        "# （もともとepsg6670なので変換は不要だが念のため明示しておく）\n",
        "\n",
        "aoi_polygon = gpd.read_file(base_dir + \"AOI.geojson\")\\\n",
        "    .to_crs(epsg=6670)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a249f1c",
      "metadata": {
        "id": "6a249f1c"
      },
      "source": [
        "GeoDataFrameの`plot`メソッドを使って，被害状況ベクタデータを表示してみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14efd319",
      "metadata": {
        "id": "14efd319"
      },
      "outputs": [],
      "source": [
        "ls_polygon.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae189935",
      "metadata": {
        "id": "ae189935"
      },
      "source": [
        "確認のため最後の5行を表示してみると，判読範囲や判読不能範囲などのデータが含まれていることがわかります．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e295a64",
      "metadata": {
        "id": "6e295a64"
      },
      "outputs": [],
      "source": [
        "ls_polygon.tail(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be607201",
      "metadata": {
        "id": "be607201"
      },
      "source": [
        "被害状況ベクタデータから必要なデータのみを取り出します．\n",
        "とりあえずポリゴンのみを抽出しましょう．\n",
        "`ls_polygon`の`geometry.type`プロパティが`Polygon`になっているのがポリゴンデータです．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "528de4b6",
      "metadata": {
        "id": "528de4b6"
      },
      "outputs": [],
      "source": [
        "ls_polygon = ls_polygon[ls_polygon.geometry.type=='Polygon']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46fc0916",
      "metadata": {
        "id": "46fc0916"
      },
      "source": [
        "ポリゴンのみ取り出せているか表示して確認します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42b74d56",
      "metadata": {
        "id": "42b74d56"
      },
      "outputs": [],
      "source": [
        "ls_polygon.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "871e2090",
      "metadata": {
        "id": "871e2090"
      },
      "source": [
        "表示されたポリゴンの属性を表示します．\n",
        "`ls_polygon`の`name`属性にポリゴンの種類が入ってるので，`unique`メソッドを使って値を確認します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18224c2c",
      "metadata": {
        "id": "18224c2c"
      },
      "outputs": [],
      "source": [
        "ls_polygon.name.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2087e835",
      "metadata": {
        "id": "2087e835"
      },
      "source": [
        "洪水流到達範囲，土砂崩壊地，判読不能範囲の3種類がありました．\n",
        "このうち土砂崩壊地のみ表示してみます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1f108b1",
      "metadata": {
        "id": "b1f108b1"
      },
      "outputs": [],
      "source": [
        "ls_polygon[ls_polygon.name=='土砂崩壊地'].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a1d2e36",
      "metadata": {
        "id": "1a1d2e36"
      },
      "source": [
        "集計用のポリゴンも表示してみます．\n",
        "集計用のポリゴンもGeoDataFrameになっていますので，`explore`メソッドを使ってインタラクティブマップに表示します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ccaf378",
      "metadata": {
        "id": "3ccaf378"
      },
      "outputs": [],
      "source": [
        "aoi_polygon.explore()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6779192",
      "metadata": {
        "id": "e6779192"
      },
      "source": [
        "この集計用メッシュごとに地形量と土砂崩壊地の有無を集計します．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccf93f1d",
      "metadata": {
        "id": "ccf93f1d"
      },
      "source": [
        "### 地形データの読み込みと確認"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fb110ca",
      "metadata": {
        "id": "1fb110ca"
      },
      "source": [
        "`rasterio`を使ってDEMを読み込みます．\n",
        "本資料で使用するDEMは[基盤地図情報](https://www.gsi.go.jp/kiban/)の数値標高モデル（DEM10B）を使用しています．\n",
        "xmlをダウンロードしてGIS Day in 東京 2019のEコース「Pythonを用いたDEM処理」のプログラム[「1_基盤地図情報の読み込み.ipynb」](https://github.com/bokutachi256/gisday2019/blob/main/1_%E5%9F%BA%E7%9B%A4%E5%9C%B0%E5%9B%B3%E6%83%85%E5%A0%B1%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF.ipynb)を使用してGeoTiffに変換しています．\n",
        "ダウンロードしたDEMのメッシュは以下です．\n",
        "\n",
        "* 503005\n",
        "* 503006\n",
        "* 503007\n",
        "* 503015\n",
        "* 503016\n",
        "* 503017\n",
        "* 503025\n",
        "* 503026\n",
        "* 503027\n",
        "* 503100\n",
        "* 503110\n",
        "* 503120\n",
        "\n",
        "GeoTiffに変換したDEMは世界測地系（JGD2011）の平面直角座標系（公共測量座標系）第Ⅱ系（epsg6670）に変換し，\n",
        "10 m解像度にリサンプリングしました．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bbd2909",
      "metadata": {
        "id": "5bbd2909"
      },
      "source": [
        "rasterioを用いてDEMを読み込みます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d105c41",
      "metadata": {
        "id": "4d105c41"
      },
      "outputs": [],
      "source": [
        "# DEMの読み込み\n",
        "dem_data = rasterio.open(base_dir + \"output_dem_reprojected.tif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28ee545a",
      "metadata": {
        "id": "28ee545a"
      },
      "source": [
        "確認のため読み込んだDEMを表示してみます．\n",
        "rasterioは多バンドデータに対応しているので，読み込んだDEMのバンドを指定する必要があります．\n",
        "バンドは一つしかないので，`dem_data.read(1)`を`imshow`で表示します．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "484dad74",
      "metadata": {
        "id": "484dad74"
      },
      "outputs": [],
      "source": [
        "# DEMの表示\n",
        "fig, ax = plt.subplots()\n",
        "img = ax.imshow(dem_data.read(1), vmin=0, vmax=1000, cmap='terrain')\n",
        "plt.title('DEM (Digital Elevation Model)')\n",
        "plt.colorbar(img, ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a2fc939",
      "metadata": {
        "id": "6a2fc939"
      },
      "source": [
        "DEM以外の地形量も読み込みます．\n",
        "読み込む地形量は以下のもので，こちらについてもGIS Day in 東京 2019 Eコース「Pythonを用いたDEM処理」のプログラムを用いて処理しています．\n",
        "\n",
        "* 傾斜量：`output_slope_deg.tif`：[（2_傾斜量と曲率の計算.ipynb）](https://github.com/bokutachi256/gisday2019/blob/main/2_%E5%82%BE%E6%96%9C%E9%87%8F%E3%81%A8%E6%9B%B2%E7%8E%87%E3%81%AE%E8%A8%88%E7%AE%97.ipynb)\n",
        "* 平面曲率（PlC）：`output_plc.tif`[（2_傾斜量と曲率の計算.ipynb）](https://github.com/bokutachi256/gisday2019/blob/main/2_%E5%82%BE%E6%96%9C%E9%87%8F%E3%81%A8%E6%9B%B2%E7%8E%87%E3%81%AE%E8%A8%88%E7%AE%97.ipynb)\n",
        "* 断面曲率（PrC）：`output_prc.tif`[（2_傾斜量と曲率の計算.ipynb）](https://github.com/bokutachi256/gisday2019/blob/main/2_%E5%82%BE%E6%96%9C%E9%87%8F%E3%81%A8%E6%9B%B2%E7%8E%87%E3%81%AE%E8%A8%88%E7%AE%97.ipynb)\n",
        "* 土砂移動指数（STI）：`output_stilog.tif`：[（4_Wetness_indexとSTIの計算.ipynb）](https://github.com/bokutachi256/gisday2019/blob/main/4_Wetness_index%E3%81%A8STI%E3%81%AE%E8%A8%88%E7%AE%97.ipynb)\n",
        "* 湿潤指数（WI）：`output_wetnessindex.tif`：[（4_Wetness_indexとSTIの計算.ipynb）](https://github.com/bokutachi256/gisday2019/blob/main/4_Wetness_index%E3%81%A8STI%E3%81%AE%E8%A8%88%E7%AE%97.ipynb)\n",
        "* 侵食高：`output_dis.tif`：[（3_接峰面と陰影図の計算.ipynb）](https://github.com/bokutachi256/gisday2019/blob/main/3_%E6%8E%A5%E5%B3%B0%E9%9D%A2%E3%81%A8%E9%99%B0%E5%BD%B1%E5%9B%B3%E3%81%AE%E8%A8%88%E7%AE%97.ipynb)\n",
        "* 陰影起伏図：`output_hillshade.tif`：[（3_接峰面と陰影図の計算.ipynb）](https://github.com/bokutachi256/gisday2019/blob/main/3_%E6%8E%A5%E5%B3%B0%E9%9D%A2%E3%81%A8%E9%99%B0%E5%BD%B1%E5%9B%B3%E3%81%AE%E8%A8%88%E7%AE%97.ipynb)\n",
        "\n",
        "侵食髙については[（3_接峰面と陰影図の計算.ipynb）](https://github.com/bokutachi256/gisday2019/blob/main/3_%E6%8E%A5%E5%B3%B0%E9%9D%A2%E3%81%A8%E9%99%B0%E5%BD%B1%E5%9B%B3%E3%81%AE%E8%A8%88%E7%AE%97.ipynb)で求めた接峰面（`output_summit.tif`）とDEM（`output_dem_reprojected.tif`）の差分です．\n",
        "差分はArcGIS ProやQGISなどのデスクトップ型GISで求められます．\n",
        "もちろんプログラムを改造しても構いません．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ece330f",
      "metadata": {
        "id": "8ece330f"
      },
      "outputs": [],
      "source": [
        "# 傾斜量，平面曲率（PlC），断面曲率（PrC），土砂移動指数（STI），\n",
        "# 湿潤指数（WI），侵食高（dis），陰影起伏図（hillshade）の読み込み\n",
        "\n",
        "slope_data = rasterio.open(base_dir + \"output_slope_deg.tif\")\n",
        "plc_data = rasterio.open(base_dir + \"output_plc.tif\")\n",
        "prc_data = rasterio.open(base_dir + \"output_prc.tif\")\n",
        "sti_data = rasterio.open(base_dir + \"output_stilog.tif\")\n",
        "wi_data= rasterio.open(base_dir + \"output_wetnessindex.tif\")\n",
        "dis_data= rasterio.open(base_dir + \"output_dis.tif\")\n",
        "hillshade_data= rasterio.open(base_dir + \"output_hillshade.tif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54970888",
      "metadata": {
        "id": "54970888"
      },
      "source": [
        "確認のため傾斜量を表示してみます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5edaee38",
      "metadata": {
        "id": "5edaee38"
      },
      "outputs": [],
      "source": [
        "# 傾斜量の表示\n",
        "fig, ax = plt.subplots()\n",
        "img = ax.imshow(slope_data.read(1), vmin=0, vmax=45, cmap='Reds')\n",
        "ax.set_title('Slope angle (deg)')\n",
        "plt.colorbar(img, ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8511f8e",
      "metadata": {
        "id": "b8511f8e"
      },
      "source": [
        "傾斜量の一部を拡大して表示してみます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28a9a60",
      "metadata": {
        "id": "d28a9a60"
      },
      "outputs": [],
      "source": [
        "# 傾斜量の一部を拡大して表示\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "img = ax.imshow(slope_data.read(1)[2000:2500, 2000:2500], vmin=0, vmax=45, cmap='Reds')\n",
        "plt.colorbar(img)\n",
        "plt.title('Slope angle (deg)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c83ff3a",
      "metadata": {
        "id": "7c83ff3a"
      },
      "source": [
        "すべての地形データを一覧表示してみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "990e8edf",
      "metadata": {
        "id": "990e8edf"
      },
      "outputs": [],
      "source": [
        "# すべての地形データを一度に表示\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "ax1 = fig.add_subplot(3, 3, 1)\n",
        "ax2 = fig.add_subplot(3, 3, 2)\n",
        "ax3 = fig.add_subplot(3, 3, 3)\n",
        "ax4 = fig.add_subplot(3, 3, 4)\n",
        "ax5 = fig.add_subplot(3, 3, 5)\n",
        "ax6 = fig.add_subplot(3, 3, 6)\n",
        "ax7 = fig.add_subplot(3, 3, 7)\n",
        "ax8 = fig.add_subplot(3, 3, 8)\n",
        "\n",
        "# DEMの表示\n",
        "img = ax1.imshow(dem_data.read(1)[2000:2500, 2000:2500], vmin=0,\n",
        "                vmax=1000, cmap='terrain')\n",
        "plt.colorbar(img, ax=ax1)\n",
        "ax1.set_title('DEM')\n",
        "\n",
        "# 陰影図の表示\n",
        "img = ax2.imshow(hillshade_data.read(1)[2000:2500, 2000:2500], vmin=0,\n",
        "                vmax=255, cmap='gray')\n",
        "plt.colorbar(img, ax=ax2)\n",
        "ax2.set_title('Hillshade')\n",
        "\n",
        "# 開析髙の表示\n",
        "img = ax3.imshow(dis_data.read(1)[2000:2500, 2000:2500], vmin=0,\n",
        "                vmax=100, cmap='Purples')\n",
        "plt.colorbar(img, ax=ax3)\n",
        "ax3.set_title('Dissection Height (m)')\n",
        "\n",
        "# 傾斜量の表示\n",
        "img = ax4.imshow(slope_data.read(1)[2000:2500, 2000:2500], vmin=0,\n",
        "                vmax=45, cmap='Reds')\n",
        "plt.colorbar(img, ax=ax4)\n",
        "ax4.set_title('Slope angle (deg)')\n",
        "\n",
        "# 平面曲率（PlC）の表示\n",
        "img = ax5.imshow(plc_data.read(1)[2000:2500, 2000:2500], vmin=-0.05,\n",
        "                vmax=0.05, cmap='bwr')\n",
        "plt.colorbar(img, ax=ax5)\n",
        "ax5.set_title('Plan Curvature (PlC)')\n",
        "\n",
        "# 断面曲率（PrC）の表示\n",
        "img = ax6.imshow(prc_data.read(1)[2000:2500, 2000:2500], vmin=-0.05,\n",
        "                vmax=0.05, cmap='bwr')\n",
        "plt.colorbar(img, ax=ax6)\n",
        "ax6.set_title('Profile Curvature (PrC)')\n",
        "\n",
        "# 土砂移動指数（STI）の表示\n",
        "img = ax7.imshow(sti_data.read(1)[2000:2500, 2000:2500], vmin=0,\n",
        "                vmax=5, cmap='Greens')\n",
        "plt.colorbar(img, ax=ax7)\n",
        "ax7.set_title('Sediment Transport Index (STI)')\n",
        "\n",
        "# 湿潤指数（WI）の表示\n",
        "img = ax8.imshow(wi_data.read(1)[2000:2500, 2000:2500], vmin=0,\n",
        "                vmax=20, cmap='Blues')\n",
        "plt.colorbar(img, ax=ax8)\n",
        "ax8.set_title('Wetness Index (WI)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe4d2b97",
      "metadata": {
        "id": "fe4d2b97"
      },
      "source": [
        "## 説明変数の準備"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0deded1b",
      "metadata": {
        "id": "0deded1b"
      },
      "source": [
        "### 地形特徴量（連続量）の集計"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f5a3aed",
      "metadata": {
        "id": "8f5a3aed"
      },
      "source": [
        "`zonal_stats`を使って集計メッシュごとに傾斜量を集計します．\n",
        "傾斜量は連続量のため，メッシュごとの最小値（`min`），最大値（`max`），平均値（`mean`），標準偏差（`std`），値域（`range`）を集計します．\n",
        "`zonal_stats`の引数は集計単位のポリゴン（`aoi_polyton`），集計するラスタデータ（`slope_data.read(1)`），\n",
        "集計するラスタデータのアフィンパラメーター（`slope_data.transform`），集計する統計量です．\n",
        "\n",
        "ここでは傾斜量を集計したいので，`rasterio`で読み込んだ傾斜量`slope_data`を指定します．\n",
        "`rasterio`で読み込んだラスタデータは多バンドになるので，どのバンドを集計するか指定する必要があります．\n",
        "傾斜量は1バンドしかないので`slope_data.read(1)`とします．\n",
        "ラスタデータのアフィンパラメーターは`transform`プロパティで取得できるので，`slope_data.transform`とします．\n",
        "集計する統計量はリストで指定します．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5129208e",
      "metadata": {
        "id": "5129208e"
      },
      "outputs": [],
      "source": [
        "# 傾斜量の集計\n",
        "stats = zonal_stats(aoi_polygon, slope_data.read(1),\n",
        "                    affine=slope_data.transform,\n",
        "                    stats=['min', 'max', 'mean', 'std', 'range'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd102ef2",
      "metadata": {
        "id": "fd102ef2"
      },
      "source": [
        "集計結果は`stats`に入るので，これをPandasのDataFrameに変換します．\n",
        "DataFrameの列名は`min`, `max`, `mean`, `std`, `range`になりますが，\n",
        "この後で他の地形特徴量を集計した時に列名が同じになってしまうので\n",
        "傾斜量の集計結果だということがわかるように列名を変更（列名に`slope_`を加える）します．\n",
        "`rename`プロパティで`inplace=True`を指定して，`slope_df`自体の列名を変更します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b10cb7",
      "metadata": {
        "id": "85b10cb7"
      },
      "outputs": [],
      "source": [
        "# 傾斜量の集計結果をdataframeに変換\n",
        "slope_df = pd.DataFrame(stats)\n",
        "# 列名の変更\n",
        "slope_df.rename(columns={'min': 'slope_min', 'max': 'slope_max',\n",
        "                        'mean': 'slope_mean', 'std': 'slope_std',\n",
        "                        'range': 'slope_range'}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca2a8c2c",
      "metadata": {
        "id": "ca2a8c2c"
      },
      "source": [
        "集計結果を確認します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30501414",
      "metadata": {
        "id": "30501414"
      },
      "outputs": [],
      "source": [
        "print(slope_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62ecebb4",
      "metadata": {
        "id": "62ecebb4"
      },
      "source": [
        "ちゃんと集計されているようです．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e344ffcd",
      "metadata": {
        "id": "e344ffcd"
      },
      "source": [
        "次に傾斜量以外の地形量も集計しましょう．\n",
        "陰影起伏は地形の概観を見るためだけに使いますので，集計の対象からは外します．\n",
        "曲率（`plc_data`と`prc_data`）は後ほど斜面形状に変換して集計するのでこちらも集計から外します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad924e72",
      "metadata": {
        "id": "ad924e72"
      },
      "outputs": [],
      "source": [
        "#  標高の集計\n",
        "stats = zonal_stats(aoi_polygon, dem_data.read(1),\n",
        "                    affine=dem_data.transform,\n",
        "                    stats=['min', 'max', 'mean', 'std', 'range'])\n",
        "dem_df = pd.DataFrame(stats)\n",
        "dem_df.rename(columns={'min': 'alt_min', 'max': 'alt_max',\n",
        "                    'mean': 'alt_mean', 'std': 'alt_std',\n",
        "                    'range': 'alt_range'}, inplace=True)\n",
        "\n",
        "#  侵食高の集計\n",
        "stats = zonal_stats(aoi_polygon, dis_data.read(1),\n",
        "                    affine=dis_data.transform,\n",
        "                    stats=['min', 'max', 'mean', 'std', 'range'])\n",
        "dis_df = pd.DataFrame(stats)\n",
        "dis_df.rename(columns={'min': 'dis_min', 'max': 'dis_max',\n",
        "                    'mean': 'dis_mean', 'std': 'dis_std',\n",
        "                    'range': 'dis_range'}, inplace=True)\n",
        "\n",
        "# STIの集計\n",
        "stats = zonal_stats(aoi_polygon, sti_data.read(1),\n",
        "                    affine=sti_data.transform,\n",
        "                    stats=['min', 'max', 'mean', 'std', 'range'])\n",
        "sti_df = pd.DataFrame(stats)\n",
        "sti_df.rename(columns={'min': 'sti_min', 'max': 'sti_max',\n",
        "                    'mean': 'sti_mean', 'std': 'sti_std',\n",
        "                    'range': 'sti_range'}, inplace=True)\n",
        "\n",
        "# WIの集計\n",
        "stats = zonal_stats(aoi_polygon, wi_data.read(1),\n",
        "                    affine=wi_data.transform,\n",
        "                    stats=['min', 'max', 'mean', 'std', 'range'])\n",
        "wi_df = pd.DataFrame(stats)\n",
        "wi_df.rename(columns={'min': 'wi_min', 'max': 'wi_max',\n",
        "                    'mean': 'wi_mean', 'std': 'wi_std',\n",
        "                    'range': 'wi_range'}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ccaec20",
      "metadata": {
        "id": "8ccaec20"
      },
      "source": [
        "集計したデータを確認してみましょう．\n",
        "ここでは侵食髙`dis_df`を表示しますが，他の地形量についても確認してみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc8a09f9",
      "metadata": {
        "id": "fc8a09f9"
      },
      "outputs": [],
      "source": [
        "print(dis_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8daee397",
      "metadata": {
        "id": "8daee397"
      },
      "source": [
        "集計した地形量をメッシュに結合します．\n",
        "集計した地形データの数はメッシュと同じなので，`pd.concat`を使ってメッシュデータに横結合します．\n",
        "\n",
        "結合したいDataFrameをリストで与え，`axis=1`として横結合を指定します．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17a8557d",
      "metadata": {
        "id": "17a8557d"
      },
      "outputs": [],
      "source": [
        "# 集計データの結合\n",
        "aoi_agg_df = pd.concat([aoi_polygon, dem_df, slope_df, dis_df, sti_df, wi_df], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d227cfaa",
      "metadata": {
        "id": "d227cfaa"
      },
      "source": [
        "### カテゴリデータ（斜面形状）の集計"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "796cf590",
      "metadata": {
        "id": "796cf590"
      },
      "source": [
        "### 曲率から斜面形状への変換"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "304f366a",
      "metadata": {
        "id": "304f366a"
      },
      "source": [
        "平面曲率（`plc_data`）と断面曲率（`prc_data`）も集計します．\n",
        "曲率は地形の平面曲率（Plan Curvature, PlC）つまり地形の水平断面（等高線）の曲率と，地形の垂直断面の曲率（Profile Curvature; PrC）を示しています．\n",
        "平面曲率が負の場合は谷型斜面（等高線が凹），0は等高線が直線，正は尾根型斜面（等高線が凸）で，\n",
        "断面曲率が負の場合は凸型斜面，0は直線斜面，正は凹型斜面となります．\n",
        "\n",
        "メッシュごとに平面曲率を集計した場合，例えばあるメッシュの尾根型斜面と谷型斜面の面積が50%ずつだった場合，\n",
        "平均を取ってしまうと0になってしまい，そのメッシュの平均的な斜面形状は直線型ということになってしまいます．\n",
        "このため，曲率の単純な統計量にはあまり意味がありません．\n",
        "これを避けるために，平面曲率と断面曲率から斜面形状を表すカテゴリ（名義尺度）データを作成し，\n",
        "メッシュ内でそれぞれの斜面形状の面積比を求めます．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e2e6181",
      "metadata": {
        "id": "2e2e6181"
      },
      "source": [
        "それでは平面曲率から斜面形状（谷型斜面，直線斜面，尾根型斜面）を求めましょう．\n",
        "平面曲率が負の場合は谷型斜面になりますが，絶対値が小さい場合はほとんど直線斜面とみなしてよいでしょう．\n",
        "このため平面曲率が-0.005未満を谷型斜面，-0.005以上0.005未満を直線斜面，0.005以上を尾根型斜面とします．\n",
        "\n",
        "`np.where`を使って平面曲率を斜面形状に再分類します．\n",
        "再分類結果は`plc_shape`とし，1を谷型斜面，2を直線斜面，3を尾根型斜面とします．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c065368",
      "metadata": {
        "id": "1c065368"
      },
      "outputs": [],
      "source": [
        "# 平面曲率（PlC）を3種類の形状に分類\n",
        "\n",
        "# -0.005未満を谷型斜面（ラベル1），-0.005〜0.005を直線斜面（ラベル2）\n",
        "# 0.005以上を尾根型斜面（ラベル3）として分類\n",
        "\n",
        "plc_shape = np.where(plc_data.read(1) < -0.005, 1, 0)\n",
        "plc_shape = np.where((plc_data.read(1) >= -0.005) & (plc_data.read(1) < 0.005)\\\n",
        "                    & (plc_shape == 0), 2, plc_shape)\n",
        "plc_shape = np.where((plc_data.read(1) >= 0.005) & (plc_shape == 0), 3, plc_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b7b80ef",
      "metadata": {
        "id": "7b7b80ef"
      },
      "source": [
        "分類した斜面形状を表示してみます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db435da0",
      "metadata": {
        "id": "db435da0"
      },
      "outputs": [],
      "source": [
        "# 分類した斜面形状を表示\n",
        "\n",
        "img = plt.imshow(plc_shape[2000:2200, 2000:2200], cmap='rainbow')\n",
        "plt.colorbar(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df8dea4",
      "metadata": {
        "id": "2df8dea4"
      },
      "source": [
        "同様に断面曲率も斜面形状に再分類します．\n",
        "-0.005未満を凸型斜面，-0.005〜0.005を直線斜面，0.005以上を凹型斜面とし，\n",
        "それぞれ1，2，3とします．\n",
        "分類した結果も表示します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d506646",
      "metadata": {
        "id": "5d506646"
      },
      "outputs": [],
      "source": [
        "# 断面曲率（PrC）を3種類の形状に分類\n",
        "\n",
        "# -0.005未満を凸斜面（ラベル1），-0.005〜0.005を直線斜面（ラベル2），\n",
        "# 0.005以上を凹斜面（ラベル3）として分類\n",
        "prc_shape = np.where(prc_data.read(1)<-0.005, 1, 0)\n",
        "prc_shape = np.where((prc_data.read(1)>=-0.005) & (prc_data.read(1)<0.005)\n",
        "                    & (prc_shape==0), 2, prc_shape)\n",
        "prc_shape = np.where((prc_data.read(1)>=0.005) & (prc_shape==0), 3, prc_shape)\n",
        "\n",
        "# 分類した斜面形状を表示\n",
        "img = plt.imshow(prc_shape[2000:2200, 2000:2200], cmap='rainbow')\n",
        "plt.colorbar(img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d6bb06a",
      "metadata": {
        "id": "7d6bb06a"
      },
      "source": [
        "作成した斜面形状データを集計しましょう．\n",
        "斜面形状はカテゴリ（質的）データなので，斜面形状ごとのピクセル数をカウントします．\n",
        "集計には量的データと同様に`zonal_stats`を使いますが，\n",
        "カテゴリデータの場合は`category=True`を指定します．\n",
        "また，数値とカテゴリの対応表をディクショナリで与えます．\n",
        "ここでは対応表を`plc_catmat`とし，`plc_catmap = {1: 'plc_valley', 2: 'plc_linear', 3: 'plc_ridge'}`とします．\n",
        "集計結果を`plc_cat_df`に格納し，`astype`メソッドを使って実数に変換します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d82d2b5",
      "metadata": {
        "id": "8d82d2b5"
      },
      "outputs": [],
      "source": [
        "# 谷型斜面（ラベル1），直線斜面（ラベル2），尾根型斜面（ラベル3）\n",
        "plc_catmap = {1: 'plc_valley', 2: 'plc_linear', 3: 'plc_ridge'}\n",
        "stats = zonal_stats(aoi_polygon, plc_shape, affine=plc_data.transform,\n",
        "                    categorical=True, category_map=plc_catmap)\n",
        "plc_cat_df = pd.DataFrame(stats).astype(float)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f04f6e00",
      "metadata": {
        "id": "f04f6e00"
      },
      "source": [
        "確認のため集計結果を表示します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13509cbc",
      "metadata": {
        "id": "13509cbc"
      },
      "outputs": [],
      "source": [
        "print(plc_cat_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be7bff9a",
      "metadata": {
        "id": "be7bff9a"
      },
      "source": [
        "`plc_valley`，`plc_linear`，`plc_ridge`の列にそれぞれ谷型斜面，直線斜面，尾根型斜面のピクセル数が入ります．\n",
        "`0`の列はいずれにも分類されなかったピクセル数です．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fb6a2dc",
      "metadata": {
        "id": "2fb6a2dc"
      },
      "source": [
        "次にそれぞれの斜面形状の割合を求めます．\n",
        "割合は`plc_valley_ratio`，`plc_linear_ratio`，`plc_ridge_ratio`に格納します．\n",
        "欠損値は`nan`になるので，`fillna`メソッドを使って0に置き換えます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b259812",
      "metadata": {
        "id": "1b259812"
      },
      "outputs": [],
      "source": [
        "# 各斜面形状の面積比を計算\n",
        "plc_cat_df['plc_valley_ratio'] = plc_cat_df['plc_valley'] /\\\n",
        "    sum(plc_cat_df.loc[0, ['plc_valley', 'plc_linear', 'plc_ridge']])\n",
        "plc_cat_df['plc_linear_ratio'] = plc_cat_df['plc_linear'] /\\\n",
        "    sum(plc_cat_df.loc[0, ['plc_valley', 'plc_linear', 'plc_ridge']])\n",
        "plc_cat_df['plc_ridge_ratio'] = plc_cat_df['plc_ridge'] /\\\n",
        "    sum(plc_cat_df.loc[0, ['plc_valley', 'plc_linear', 'plc_ridge']])\n",
        "\n",
        "# 欠損値を0で埋める\n",
        "plc_cat_df = plc_cat_df.fillna(0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b57ad79c",
      "metadata": {
        "id": "b57ad79c"
      },
      "source": [
        "求めた面積比を表示してみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "184d546f",
      "metadata": {
        "id": "184d546f"
      },
      "outputs": [],
      "source": [
        "print(plc_cat_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaf624d6",
      "metadata": {
        "id": "eaf624d6"
      },
      "source": [
        "斜面形状の面積比をメッシュに結合します．\n",
        "必要なのは面積比（`plc_valley_ratio`，`plc_linear_ratio`，`plc_ridge_ratio`）のみなので，\n",
        "これらを`concat`を使って集計結果のメッシュデータ`aoi_agg_df`に横結合します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0db1da4c",
      "metadata": {
        "id": "0db1da4c"
      },
      "outputs": [],
      "source": [
        "# 斜面形状の面積比をメッシュに結合する\n",
        "\n",
        "aoi_agg_df = pd.concat([aoi_agg_df,\n",
        "                        plc_cat_df[['plc_valley_ratio', 'plc_linear_ratio',\\\n",
        "                                    'plc_ridge_ratio']]],\n",
        "                        axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32b537f0",
      "metadata": {
        "id": "32b537f0"
      },
      "source": [
        "断面曲率も斜面形状ごとの面積比を求め，集計メッシュデータに横結合します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2710a4f2",
      "metadata": {
        "id": "2710a4f2"
      },
      "outputs": [],
      "source": [
        "# 断面曲率も斜面形状# （凸斜面（ラベル1），直線斜面（ラベル2），凹斜面（ラベル3））に変換して面積率を集計する\n",
        "\n",
        "# 凸斜面（ラベル1），直線斜面（ラベル2），凹斜面（ラベル3）\n",
        "prc_catmap = {1: 'prc_convex', 2: 'prc_linear', 3: 'prc_concave'}\n",
        "stats = zonal_stats(aoi_polygon, prc_shape, affine=prc_data.transform,\n",
        "                    categorical=True, category_map=prc_catmap)\n",
        "prc_cat_df = pd.DataFrame(stats).astype(float)\n",
        "\n",
        "# 各斜面形状の面積比を計算\n",
        "prc_cat_df['prc_convex_ratio'] = prc_cat_df['prc_convex'] /\\\n",
        "    sum(prc_cat_df.loc[0, ['prc_convex', 'prc_linear', 'prc_concave']])\n",
        "prc_cat_df['prc_linear_ratio'] = prc_cat_df['prc_linear'] /\\\n",
        "    sum(prc_cat_df.loc[0, ['prc_convex', 'prc_linear', 'prc_concave']])\n",
        "prc_cat_df['prc_concave_ratio'] = prc_cat_df['prc_concave'] /\\\n",
        "    sum(prc_cat_df.loc[0, ['prc_convex', 'prc_linear', 'prc_concave']])\n",
        "\n",
        "# 欠損値を0で埋める\n",
        "prc_cat_df = prc_cat_df.fillna(0.0)\n",
        "\n",
        "# 斜面形状の面積比をメッシュに結合する\n",
        "aoi_agg_df = pd.concat([aoi_agg_df,\n",
        "                        prc_cat_df[['prc_convex_ratio', 'prc_linear_ratio',\\\n",
        "                                    'prc_concave_ratio']]],\n",
        "                        axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c304030e",
      "metadata": {
        "id": "c304030e"
      },
      "source": [
        "結合したデータをマップ表示して確認しましょう．\n",
        "ここでは例として標高の値域（`alt_range`）を表示します．\n",
        "ほかの値も表示してみてください．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75c9dd33",
      "metadata": {
        "id": "75c9dd33"
      },
      "outputs": [],
      "source": [
        "aoi_agg_df.plot(column='alt_range', legend=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e75af4cd",
      "metadata": {
        "id": "e75af4cd"
      },
      "source": [
        "## 目的変数の準備"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "074403d6",
      "metadata": {
        "id": "074403d6"
      },
      "source": [
        "この資料では，土砂崩壊の有無を目的変数として判別モデルを作成します．\n",
        "土砂崩壊はベクタデータとして与えられており，\n",
        "これをラスタ型データに変換した後にメッシュごとに面積比を集計し，\n",
        "メッシュ中の一定面積以上に土砂災害のあるメッシュを「土砂崩壊あり」のメッシュとします．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d5c1c49",
      "metadata": {
        "id": "6d5c1c49"
      },
      "source": [
        "### 目的変数を集計する"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ed4df06",
      "metadata": {
        "id": "1ed4df06"
      },
      "source": [
        "被害状況ベクタデータからポリゴンのみを抽出したデータ`ls_polygon`は`name`列が災害の種別を表しています．\n",
        "これらのポリゴンをラスタ型に変換するために，災害の種別のラベルを整数型で与えます．\n",
        "具体的には「土砂崩壊地」を`1`，「洪水流到達範囲」を`2`，これ以外のポリゴンは`0`にします．\n",
        "ラベルは新しい列`cat`に格納します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e2cf49b",
      "metadata": {
        "id": "8e2cf49b"
      },
      "outputs": [],
      "source": [
        "print(ls_polygon.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7836a1d",
      "metadata": {
        "id": "e7836a1d"
      },
      "outputs": [],
      "source": [
        "# 教師データにラベルを加える\n",
        "# 土砂崩壊地ポリゴンのcatを1，洪水流到達範囲ポリゴンのcatを2に設定\n",
        "ls_polygon['cat'] = 0\n",
        "ls_polygon.loc[ls_polygon['name']=='土砂崩壊地', 'cat'] = 1\n",
        "ls_polygon.loc[ls_polygon['name']=='洪水流到達範囲', 'cat'] = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40cc3394",
      "metadata": {
        "id": "40cc3394"
      },
      "source": [
        "次にラベル付けした被害状況ベクタデータをラスタデータに変換します．\n",
        "変換したラスタデータの座標系・測地系はDEMなどと同じ平面直角座標系第Ⅱ系・JGD2011（epsg6670）で，解像度も同じ10mにします．\n",
        "\n",
        "ラスタへの変換は`make_geocube`を使います．\n",
        "`make_geocube`の引数としては以下になります．\n",
        "変換するベクタデータを`vector_data=ls_polygon`，\n",
        "変換後のラスタデータのCRSを`output_crs='epsg:6670'`，\n",
        "ラスタに埋め込む値のある列を`measurements=['cat']`，\n",
        "ラスタの解像度を`resolution=(-10, 10)`，\n",
        "`fill=0`でポリゴンのない場所の値を0で埋めます．\n",
        "\n",
        "解像度の指定ですが，南北方向はマイナスをつける必要があります．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffe24184",
      "metadata": {
        "id": "ffe24184"
      },
      "outputs": [],
      "source": [
        "# resolutionのy方向はマイナスにする\n",
        "ls_grid = make_geocube(\n",
        "    vector_data=ls_polygon,\n",
        "    output_crs='epsg:6670',\n",
        "    measurements=['cat'],\n",
        "    resolution=(-10, 10),\n",
        "    fill=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf65ade7",
      "metadata": {
        "id": "cf65ade7"
      },
      "source": [
        "作成したラスタデータは`ls_grid`に格納します．\n",
        "`ls_grid`はxarray型式になるので，ラスタデータ自体は`ls_grid['cat']`でアクセスできます．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3a476f2",
      "metadata": {
        "id": "c3a476f2"
      },
      "source": [
        "`rio.to_raster`メソッドを使って作成した災害状況ラスタをGeoTIFFで保存します．\n",
        "保存するファイル名は`landslide_classification.tif`です．\n",
        "また，データのタイプを16ビット整数（`dtype='int16'`）にします．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a6cc072",
      "metadata": {
        "id": "5a6cc072"
      },
      "outputs": [],
      "source": [
        "# ラスター化した災害状況データをGeoTIFF形式で保存\n",
        "ls_grid['cat'].rio.to_raster(base_dir + \"landslide_classification.tif\",\n",
        "                            driver='GTiff', dtype='int16')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5d36485",
      "metadata": {
        "id": "f5d36485"
      },
      "source": [
        "保存した災害状況ラスタを明示的に読み込みます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eb3e41f",
      "metadata": {
        "id": "5eb3e41f"
      },
      "outputs": [],
      "source": [
        "ls_data = rasterio.open(base_dir + \"landslide_classification.tif\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6f943eb",
      "metadata": {
        "id": "d6f943eb"
      },
      "source": [
        "確認のため災害状況ラスタを表示します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aea32f2",
      "metadata": {
        "id": "3aea32f2"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "img = ax.imshow(ls_data.read(1), vmin=0, vmax=2, cmap='rainbow')\n",
        "plt.title('Landslide Classification')\n",
        "plt.colorbar(img, ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "964d56b7",
      "metadata": {
        "id": "964d56b7"
      },
      "source": [
        "土砂崩壊地が水色（1），洪水流到達範囲が赤（2），それ以外が紫（0）となっています．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17286fb1",
      "metadata": {
        "id": "17286fb1"
      },
      "source": [
        "災害状況ラスタはカテゴリーデータ（土砂崩壊地と洪水到達範囲）になっているため，\n",
        "曲率を元にした斜面形状データと同様の集計をおこない，災害状況ごとの面積比を求めます．\n",
        "集計メッシュへの結合まで一気にやってしまいます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2daa600",
      "metadata": {
        "id": "d2daa600"
      },
      "outputs": [],
      "source": [
        "# 災害状況ラスタをメッシュごとに集計する\n",
        "\n",
        "ls_catmap = {0: 'none', 1: 'landslide', 2: 'flood'}\n",
        "stats = zonal_stats(aoi_polygon, ls_data.read(1),\n",
        "                    affine=ls_data.transform, categorical=True,\n",
        "                    category_map=ls_catmap)\n",
        "ls_cat_df = pd.DataFrame(stats).astype(float)\n",
        "# 欠損値を0で埋める\n",
        "ls_cat_df = ls_cat_df.fillna(0.0)\n",
        "# 災害別の面積比を計算\n",
        "ls_cat_df['none_ratio'] = ls_cat_df['none'] /\\\n",
        "    sum(ls_cat_df.loc[0, ['none', 'flood', 'landslide']])\n",
        "ls_cat_df['flood_ratio'] = ls_cat_df['flood'] /\\\n",
        "    sum(ls_cat_df.loc[0, ['none', 'flood', 'landslide']])\n",
        "ls_cat_df['landslide_ratio'] = ls_cat_df['landslide'] /\\\n",
        "    sum(ls_cat_df.loc[0, ['none', 'flood', 'landslide']])\n",
        "# 災害別の面積比をメッシュに結合\n",
        "aoi_agg_df = pd.concat([aoi_agg_df,\n",
        "    ls_cat_df[['none_ratio', 'flood_ratio', 'landslide_ratio']]], axis=1)\n",
        "\n",
        "# 集計済みメッシュの欠損値とInfを0で埋める\n",
        "aoi_agg_df.fillna(0.0)\n",
        "aoi_agg_df.replace([np.inf, -np.inf], 0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2096acc4",
      "metadata": {
        "id": "2096acc4"
      },
      "source": [
        "これで機械学習のためのデータが完成しました．\n",
        "`explore`メソッドを使ってインタラクティブマップを作成しデータを確認してみます．\n",
        "ここでは背景画像として地理院タイルの淡色地図，陰影起伏図と，平成29年7月九州北部豪雨のオルソ画像を使っています．\n",
        "これらに土砂崩壊地ポリゴンと集計メッシュの土砂崩壊面積率を重ねてみました．\n",
        "\n",
        "タイルを多用しているので動作が遅くなるかもしれません．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "366992eb",
      "metadata": {
        "id": "366992eb"
      },
      "outputs": [],
      "source": [
        "mapcenter = [33.416937,130.707376]\n",
        "\n",
        "m = folium.Map(\n",
        "    location=mapcenter,\n",
        "    zoom_start=13\n",
        ")\n",
        "\n",
        "folium.raster_layers.TileLayer(\n",
        "    tiles='https://cyberjapandata.gsi.go.jp/xyz/pale/{z}/{x}/{y}.png',\n",
        "    attr='&copy; <a href=\"https://maps.gsi.go.jp/development/ichiran.html\">\\\n",
        "        地理院タイル</a>',\n",
        "    name='淡色地図'\n",
        ").add_to(m)\n",
        "\n",
        "folium.raster_layers.TileLayer(\n",
        "    tiles='https://cyberjapandata.gsi.go.jp/xyz/hillshademap/{z}/{x}/{y}.png',\n",
        "    attr='&copy; <a href=\"https://maps.gsi.go.jp/development/ichiran.html\">\\\n",
        "        地理院タイル</a>',\n",
        "    name='陰影起伏図'\n",
        ").add_to(m)\n",
        "\n",
        "folium.raster_layers.TileLayer(\n",
        "    tiles='https://cyberjapandata.gsi.go.jp/xyz/20170705typhoon3_0713dol1/{z}/{x}/{y}.png',\n",
        "    attr='&copy; <a href=\"https://maps.gsi.go.jp/development/ichiran.html\">\\\n",
        "        地理院タイル</a>',\n",
        "    name='平成29年7月九州北部豪雨 空中写真（朝倉地区）（2017年7月13日撮影）'\n",
        ").add_to(m)\n",
        "\n",
        "folium.raster_layers.TileLayer(\n",
        "    tiles='https://cyberjapandata.gsi.go.jp/xyz/20170705typhoon3_0713dol2/{z}/{x}/{y}.png',\n",
        "    attr='&copy; <a href=\"https://maps.gsi.go.jp/development/ichiran.html\">\\\n",
        "        地理院タイル</a>',\n",
        "    name='平成29年7月九州北部豪雨 空中写真（東峰地区）（2017年7月13日撮影）'\n",
        ").add_to(m)\n",
        "\n",
        "ls_polygon[ls_polygon['cat']==1].to_crs(epsg=3857).explore(\n",
        "# ls_polygon.to_crs(epsg=3857).explore(\n",
        "    m=m,\n",
        "    color='red',\n",
        "    name='土砂崩壊地'\n",
        ")\n",
        "\n",
        "aoi_agg_df.to_crs(epsg=3857).explore(\n",
        "    m=m,\n",
        "    column='landslide_ratio',\n",
        "    name='土砂崩壊地面積率'\n",
        ")\n",
        "\n",
        "folium.LayerControl().add_to(m)\n",
        "display(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24f4d76d",
      "metadata": {
        "id": "24f4d76d"
      },
      "source": [
        "## 決定木による分類・予測モデルの作成"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "789f633c",
      "metadata": {
        "id": "789f633c"
      },
      "source": [
        "### 決定木の作成"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acb23cc7",
      "metadata": {
        "id": "acb23cc7"
      },
      "source": [
        "データが揃ったので決定木を作っていきましょう．\n",
        "決定木には説明変数と目的変数が必要になります．\n",
        "説明変数はメッシュごとに集計した地形量，目的変数はメッシュごとの土砂崩壊地の有無です．\n",
        "Pythonのscikit-learnを使った機械学習では慣例として説明変数を`X`，目的変数を`y`とします．\n",
        "\n",
        "まずは集計メッシュから説明変数`X`を作成します．\n",
        "必要な項目は地形量の記述統計量と斜面形状の面積比です．\n",
        "集計メッシュ`aoi_agg_df`のデータのうち，説明変数の列名をリスト形式で用意します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59644b8c",
      "metadata": {
        "id": "59644b8c"
      },
      "outputs": [],
      "source": [
        "exp_val = ['alt_min', 'alt_max', 'alt_mean', 'alt_std', 'alt_range',\n",
        "    'slope_min', 'slope_max', 'slope_mean', 'slope_std', 'slope_range',\n",
        "    'dis_min', 'dis_max', 'dis_mean', 'dis_std', 'dis_range', 'sti_min',\n",
        "    'sti_max', 'sti_mean', 'sti_std', 'sti_range', 'wi_min', 'wi_max',\n",
        "    'wi_mean', 'wi_std', 'wi_range', 'plc_valley_ratio', 'plc_linear_ratio',\n",
        "    'plc_ridge_ratio', 'prc_convex_ratio', 'prc_linear_ratio', 'prc_concave_ratio']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0392125b",
      "metadata": {
        "id": "0392125b"
      },
      "source": [
        "`X`に集計メッシュのうち，説明変数として必要な列のみをコピーします．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "366dfa54",
      "metadata": {
        "id": "366dfa54"
      },
      "outputs": [],
      "source": [
        "X =  aoi_agg_df[exp_val]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ad8b3e8",
      "metadata": {
        "id": "0ad8b3e8"
      },
      "source": [
        "次に目的変数を作成します．\n",
        "目的変数はメッシュごとの土砂崩壊の有無になるので，\n",
        "土砂崩壊地面積率が一定の値以上のメッシュを「土砂崩壊あり」とします．\n",
        "ここでは土砂崩壊地の面積率が0.1（10%）以上のメッシュを崩壊地ありメッシュとし，\n",
        "新しい列`landslide`に1を入れ，土砂崩壊地なしのメッシュには0を入れます．\n",
        "\n",
        "土砂崩壊地面積率の閾値については決まった値はありません．\n",
        "厳しくするのであれば面積率を大きくしてもよいでしょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37e9318b",
      "metadata": {
        "id": "37e9318b"
      },
      "outputs": [],
      "source": [
        "aoi_agg_df.loc[aoi_agg_df['landslide_ratio'] > 0.1, 'landslide'] = 1\n",
        "aoi_agg_df = aoi_agg_df.fillna(0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2c24fc1",
      "metadata": {
        "id": "d2c24fc1"
      },
      "source": [
        "次に目的変数`y`を作成します．\n",
        "前のステップで作成した`aoi_agg_df`の`landslide`列をそのまま`y`にコピーします．\n",
        "念のため型を整数に変換します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f295bb61",
      "metadata": {
        "id": "f295bb61"
      },
      "outputs": [],
      "source": [
        "y = aoi_agg_df['landslide'].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19daf211",
      "metadata": {
        "id": "19daf211"
      },
      "source": [
        "説明変数と目的変数が揃いました．\n",
        "次は実際に決定木を作成します．\n",
        "\n",
        "決定木の作成には説明変数と目的変数を学習（トレーニング）データと検証（テスト）データに分ける必要があります．\n",
        "学習データで決定木を作成し，作成した決定木に検証データを適用して決定木の性能を評価します．\n",
        "このため，学習データと検証データは独立している（重複していない）必要があります．\n",
        "\n",
        "一般的に学習データは検証データよりも量を多くします．\n",
        "ここでは全データのうち75％を学習データ，残りの25%を検証データにしてみましょう．\n",
        "説明変数の学習データを`X_train`，説明変数の検証データを`X_test`，目的変数の学習データを`y_train`，目的変数の検証データを`y_test`とします．\n",
        "学習データと検証データの分割には`train_test_split`を使います．\n",
        "`train_test_split`は分割したい説明変数（`X`）と目的変数（`y`），検証データの割合（`test_size=0.25`），\n",
        "分割用乱数のシード（`random_state=123`），\n",
        "層化分割の有無（`stratify=y`）を指定します．\n",
        "\n",
        "`train_test_split`はランダムサンプリングにより学習データと検証データを分割するため，\n",
        "実行するたびに異なる学習データと検証データが生成されます．\n",
        "このため，実行するたびに作成される決定木が異なり，モデルのチューニングがしにくくなります．\n",
        "分割用乱数のシードを指定すると，同じシードの値を指定している限り同じ乱数が生成されるため，\n",
        "同一の学習データと検証データで決定木を作成することができます．\n",
        "\n",
        "また目的変数のクラス（値）に不均衡がある場合，学習データと検証データの中の土砂崩壊の有無の数が異なってしまうことがあります．\n",
        "この状態で学習・検証を行っても正しい結果を得ることができません．\n",
        "`stratify=y`として層化分割を行うことにより，元データの土砂災害の有無の比率を保ったまま学習データと検証データに分けることができます．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa86702e",
      "metadata": {
        "id": "fa86702e"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test =\\\n",
        "    train_test_split(X, y, test_size=0.25, random_state=123, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f79f263",
      "metadata": {
        "id": "5f79f263"
      },
      "source": [
        "それではいよいよ決定木を作成します．\n",
        "作成の手順は以下です．\n",
        "\n",
        "1. 決定木の設定（ハイパーパラメーターの設定）を行う\n",
        "2. 設定に基づいて学習データから決定木を作成する\n",
        "3. 作成した決定木に検証データを適用する\n",
        "4. 学習結果と検証結果の正解率を検討する\n",
        "5. 混同行列（confusion matrix）と各種評価指標からモデルの性能を検討する\n",
        "6. 決定木を作成して分類プロセスを検討する\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81eb37a6",
      "metadata": {
        "id": "81eb37a6"
      },
      "source": [
        "`DecisionTreeClassifier`を使って決定木の設定を行います．\n",
        "ここではシンプルに2項目のみ設定します．\n",
        "`max_depth`は作成する決定木の最大の深さで，ここでは3とします．\n",
        "`random_state`は乱数のシードで，同じ値を設定することにより同じ結果が得られるようにします．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9caadb6b",
      "metadata": {
        "id": "9caadb6b"
      },
      "outputs": [],
      "source": [
        "model = DecisionTreeClassifier(max_depth=3, random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f925a540",
      "metadata": {
        "id": "f925a540"
      },
      "source": [
        "`model.fit`を使って学習します．\n",
        "引数は学習用の説明変数と目的変数です．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1120ed7e",
      "metadata": {
        "id": "1120ed7e"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26d08a52",
      "metadata": {
        "id": "26d08a52"
      },
      "source": [
        "作成した決定木を検証データに適用します．\n",
        "こちらは`predict`メソッドを使い，検証用説明変数を指定します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7afff45",
      "metadata": {
        "id": "c7afff45"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b4e53f7",
      "metadata": {
        "id": "8b4e53f7"
      },
      "source": [
        "以上で決定木が作成されました．\n",
        "結果の検証をしてみましょう．\n",
        "まずは学習データと検証データの正解率を表示します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9996bb9f",
      "metadata": {
        "id": "9996bb9f"
      },
      "outputs": [],
      "source": [
        "print(\"学習データの正解率\", model.score(X_train, y_train))\n",
        "print(\"検証データの正解率\", model.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db43c115",
      "metadata": {
        "id": "db43c115"
      },
      "source": [
        "学習データと検証データの両者とも正解率は約0.82となっています．\n",
        "このことから，学習データと検証データの土砂崩壊地の有無は，\n",
        "82%ほどが正しく分類されていることがわかります．\n",
        "\n",
        "次は82%の正解率の内訳について，混同行列と各種評価指標から検討していきます．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c4caf7d",
      "metadata": {
        "id": "4c4caf7d"
      },
      "source": [
        "混同行列（confusion matrix）は実際の値と予測値の値を行列で示したもので，\n",
        "ここではメッシュごとの土砂崩壊の有無（「実際の値」とします）と\n",
        "決定木をたどって予測された土砂崩壊の有無（「予測値」とします）の行列です．\n",
        "目的変数が土砂崩壊の有無の2値なので，混同行列も2*2の行列になります．\n",
        "\n",
        "混同行列は`confusion_matrix`で作成します．\n",
        "引数は目的変数の学習データと目的変数の予測値です．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13322aa5",
      "metadata": {
        "id": "13322aa5"
      },
      "outputs": [],
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d871fee9",
      "metadata": {
        "id": "d871fee9"
      },
      "source": [
        "以上のようになりました．\n",
        "これは以下のように読み取れます．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f38ea24d",
      "metadata": {
        "id": "f38ea24d"
      },
      "source": [
        "|      |      |予測 |  |\n",
        "| ---- | ---- | ---- | ---- |\n",
        "|      |      | なし | あり |\n",
        "| 実際 | なし | 2186 | 1    |\n",
        "|  | あり | 477  | 0    |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa92721b",
      "metadata": {
        "id": "aa92721b"
      },
      "source": [
        "* 検証用データは2186+477+1+0=2664サンプルあり，そのうち2186+1=2187サンプルが土砂崩壊なし，477+0=477サンプルが土砂崩壊ありだった．これが「実際」となる．\n",
        "* 検証用データを決定木に適用した結果，土砂災害なしが2186+477=2663サンプル，土砂災害ありが1+0=1サンプルとなった．これが「予測」となる．\n",
        "* 検証データの正解率は(2186+0)/(2186+477+1+0)=0.820570570570571になる．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4929156e",
      "metadata": {
        "id": "4929156e"
      },
      "source": [
        "決定木の性能を表す指標を表示してみましょう．\n",
        "`classification_report`に目的変数の検証データ（`y-test`）と目的変数の予測値（`y_pred`）を与えます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42cf7bc8",
      "metadata": {
        "id": "42cf7bc8"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred,\n",
        "                            target_names=['LS-no', 'LS-yes'] ))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fa28c64",
      "metadata": {
        "id": "5fa28c64"
      },
      "source": [
        "いくつか指標が示されていますが，ここではprecisionを考えてみましょう．\n",
        "precisionは予測されたものと実際の比を示します．\n",
        "混同行列からLS-no（土砂崩壊なし）と予測されたサンプル数は2186+477=2663サンプル，実際にLS-noだったサンプル数は2186+1=2187なので，\n",
        "LS_noのprecisionは2187/2663=0.8212となります．\n",
        "同様にLS-yes（土砂崩壊なし）のprecisionは(1+0)/(477+0)=0.00です．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "676edf65",
      "metadata": {
        "id": "676edf65"
      },
      "source": [
        "`tree_plot`を使って決定木を表示します．\n",
        "主な引数は説明変数のリスト（`feature_name=exp_val`），目的変数のクラス名（`class_names=[\"LS-no\", \"LS-yes\"]`），\n",
        "ノード番号（`node_ids=True`）です．\n",
        "`filled=True`を指定するとクラスとgini不純度の値で塗りつぶし色が変わります．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb2edbe3",
      "metadata": {
        "id": "eb2edbe3"
      },
      "outputs": [],
      "source": [
        "# 決定木を表示する\n",
        "plt.figure(figsize=(15, 10))\n",
        "tree.plot_tree(model, feature_names=exp_val,\n",
        "                class_names=[\"LS-no\", \"LS-yes\"], filled=True, node_ids=True)\n",
        "plt.title(\"Decision Tree\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6d81154",
      "metadata": {
        "id": "f6d81154"
      },
      "source": [
        "`max_depth=3`にしたので4段（最上位に加えて3段）のツリーができています．\n",
        "ツリーを構成する四角をノード（node）と呼び，最末端のノードを葉ノード（leaf node）と呼びます．\n",
        "各ノードにはノード番号（`node`），分岐の際に参照される説明変数名としきい値，gini不純度（`gini`），ノードに含まれるサンプル数（`sample`）とその内訳（`value`），\n",
        "内訳のうち最大クラスのクラス名（`class`）が書かれています．\n",
        "ノードからは下向きに2本の矢印が書かれており，しきい値を満たすと左下（`True`），満たさない場合は右下（`False`）に進みます．\n",
        "ノードの色はノードのクラス（`class`）によってオレンジ（土砂崩壊なし`calss=LS_no`）と青（土砂崩壊なし`calss=LS_yes`）に塗られ，\n",
        "色の濃さはgini不純度が小さい（0に近い）ほど濃くなります．\n",
        "\n",
        "学習用データと検証用データの両者とも，メッシュごとに最上位のノードから決定木に通され，\n",
        "分岐条件に従っていずれかの葉ノードにつきます．\n",
        "葉ノードに着いたときに予測値として葉ノードのクラスが与えられます．\n",
        "\n",
        "まず最上位のノードを見てみましょう．\n",
        "このノードに含まれるサンプル数（`samples`）は7992個で，内訳（`value`）は土砂崩壊なしが6559，土砂崩壊ありが1433個です．\n",
        "gini不純度は内訳（土砂崩壊の有無の数）から求まる指標で，内訳が偏っている場合は0に近くなり，偏りがない場合は1（内訳が2値の場合は最大で0.5）になります．\n",
        "最上位ノードでは土砂崩壊なしに偏っているためにgini不純度が0.294となっています．\n",
        "また，このノードの内訳（`values`）は土砂崩壊なしが多いためクラス（`class`）が`LS-no`になります．\n",
        "最上位ノードの分岐条件は侵食高の最大値（`dis_max`）が34.408以下かどうかです．\n",
        "条件を満たす場合（`True`）は左下の1番ノードに進み，満たさない場合（`False`）は右下の8番ノードに進みます．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36051bd4",
      "metadata": {
        "id": "36051bd4"
      },
      "source": [
        "決定木の全体を見てみましょう．\n",
        "8個ある葉ノードのうち，7個が土砂崩壊なし（`LS-no`）でわずか1個（4番ノード）が土砂崩壊あり（`LS-yes`）です．\n",
        "4番ノードの内訳（`values`）を見てみると，土砂崩壊なしが1，ありが3でサンプル数が非常に少なく，かろうじて土砂崩壊ありのノードになっています．\n",
        "むしろ4番ノード以外の葉ノード（いずれも土砂崩壊なしになる）に含まれる土砂崩壊ありのサンプルの方が多いのですが，\n",
        "土砂崩壊なしのサンプルの方が数が多いために埋もれてしまっています．\n",
        "\n",
        "以上のことから，この決定木は正解率が0.82で一見よい結果を得られているように思えますが，ほとんどを土砂災害なしに分類する決定木になっているため土砂崩壊を正確に予測することができません．\n",
        "これはなぜでしょうか．\n",
        "\n",
        "一番大きな原因はもともと土砂崩壊ありのメッシュがなしのメッシュよりもかなり少ないということがあります．\n",
        "学習データ全体で7992サンプルありますが，このうち土砂崩壊ありメッシュは1433サンプルでわずか18%ほどです．\n",
        "つまりすべての葉ノードが土砂崩壊なしになる決定木が作られて\n",
        "18%の土砂崩壊ありメッシュがすべて土砂崩壊なしに誤って予測されても，\n",
        "残り82%の土砂崩壊なしが正しく予測されるため全体の正解率は0.82となります．\n",
        "\n",
        "結果的にこの決定木は「土砂崩壊がないメッシュ」を判別するモデルになっています．\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d0dede5",
      "metadata": {
        "id": "6d0dede5"
      },
      "source": [
        "### 決定木のチューニング"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af4b285f",
      "metadata": {
        "id": "af4b285f"
      },
      "source": [
        "#### 土砂災害ありとなしの数の違いを考慮する"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed2304d0",
      "metadata": {
        "id": "ed2304d0"
      },
      "source": [
        "作成した決定木は思った通りの性能が出なかったので，チューニングを行っていきます．\n",
        "\n",
        "まず最初に土砂崩壊の有無に差があることを解決しましょう．\n",
        "`DecisionTreeClassifier`の引数に`class_weight='balanced'`を指定します．\n",
        "こうすることにより目的変数の偏りをある程度解消することができます．\n",
        "\n",
        "決定木を実行して混同行列と分類レポートを表示します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55080326",
      "metadata": {
        "id": "55080326"
      },
      "outputs": [],
      "source": [
        "# 土砂災害ありメッシュとなしメッシュの数の違いを考慮する\n",
        "model = DecisionTreeClassifier(class_weight='balanced',\n",
        "                                max_depth=3, random_state=123)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"学習データの正解率\", model.score(X_train, y_train))\n",
        "print(\"検証データの正解率\", model.score(X_test, y_test))\n",
        "\n",
        "print(\"混同行列\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"分類レポート\")\n",
        "print(classification_report(y_test, y_pred, target_names=['LS-no', 'LS-yes'] ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0f180d0",
      "metadata": {
        "id": "e0f180d0"
      },
      "source": [
        "学習データ・検証データ共に正解率は0.57前後になりました．\n",
        "最初に作成した決定木よりも数字は落ちています．\n",
        "混同行列を見てみましょう．\n",
        "\n",
        "2値の混同行列はこのような構造をしています．\n",
        "\n",
        "|      |      |予測 |  |\n",
        "| ---- | ---- | ---- | ---- |\n",
        "|      |      | なし | あり |\n",
        "| 実際 | なし | TN | FP    |\n",
        "|  | あり | FN  | TP    |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fedf085",
      "metadata": {
        "id": "1fedf085"
      },
      "source": [
        "TNはTrue Negative，FPはFalse Positive，FNはFalse NegativTrueはTrue Positiveの略です．\n",
        "Positiveは陽性（注目している事象が発現していること．ここでは土砂崩壊が発生していることをあらわす），Negativeは陰性（注目している事象が発現していないこと，ここでは土砂崩壊が発生していないことを表す）で，Trueは真，Falseは偽です．\n",
        "\n",
        "今回作成した決定木の混同行列をこれに当てはめてみるとTN（真に土砂崩壊なし）が1148，TP（真に土砂崩壊あり）が359になっており，この2個が正解になります．\n",
        "正解率（accuracy）は(TN+TP)/(TN+FN+FP+TP)で求まるため(1148+359)/(1148+118+1039+359)=0.565690となります．\n",
        "precisionは(TP)/(TP+FP)なので土砂崩壊あり（`LS_yes`）のprecisionは359/(1039+359)=2.2567954（約0.26）になります．\n",
        "同様に土砂崩壊なし（`LS-no`）のprecisionは(TN)/(TN+FN)なので1148/(1148+118)=0.906793（約0.91）です．\n",
        "最初に作成した決定木に比べると正解率は落ちていますが，土砂崩壊ありを判別できる決定木になっています．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0227129f",
      "metadata": {
        "id": "0227129f"
      },
      "source": [
        "決定木も表示してみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f8508cb",
      "metadata": {
        "id": "6f8508cb"
      },
      "outputs": [],
      "source": [
        "# 決定木を表示する\n",
        "plt.figure(figsize=(15, 10))\n",
        "tree.plot_tree(model, feature_names=exp_val,\n",
        "                class_names=[\"LS-no\", \"LS-yes\"], filled=True, node_ids=True)\n",
        "plt.title(\"Decision Tree\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe1f9699",
      "metadata": {
        "id": "fe1f9699"
      },
      "source": [
        "土砂崩壊ありの葉ノードは相変わらず一つだけ（ノード11）です．\n",
        "各ノードの分岐条件を見ていきます．\n",
        "最上位ノードの分岐条件は標高の値域（`alt_range`）で閾値は18.832です．\n",
        "18.832以下の場合は左下（ノード1）に進み，ノード1より下のノードはすべて土砂災害なし（`class=LS-no`）です．\n",
        "つまり，標高の値域が18.832以下では土砂崩壊が起こりにくいと言えます．\n",
        "\n",
        "ノード8以下は土砂崩壊なし（`class=LS-no`）と土砂崩壊あり（`class=LS-yes`）が混在しており，\n",
        "ノード8以下でさらに細かく分かれていきます．\n",
        "ノード8の分岐条件を見てみると標高の最大値（`alt_max`）が出てきており，閾値は528.699となっています．\n",
        "同様にノード12の分岐条件を見てみると標高の最小値（`alt_min`）です．\n",
        "一見良さそうですが，実はここに問題点が隠れています．\n",
        "\n",
        "例えば標高が最大で1000mある山地で土砂崩壊があったとしましょう．\n",
        "この場合，土砂崩壊のあるメッシュの標高の最大値や最小値が1000を超えることはありません．\n",
        "このように絶対的な標高に関する地形量を入れてしまうと，対象地域の高度分布に特化した分岐条件が出てしまうことがあります．\n",
        "このため，他の地域でも適用できる汎用的な決定木を作成することができなくなります．\n",
        "このため説明変数を取捨選択する必要があります．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2973232d",
      "metadata": {
        "id": "2973232d"
      },
      "source": [
        "#### 説明変数の取捨選択"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1a78f1a",
      "metadata": {
        "id": "c1a78f1a"
      },
      "source": [
        "絶対的な標高に関する地形量を説明変数から除外します．\n",
        "除外する地形量は標高の最小値（`alt_min`），標高の最大値（`alt_max`），標高の平均値（`alt_mean`）です．\n",
        "標高の標準偏差（`alt_std`）と標高の値域（`alt_range`）はメッシュ内標高の相対的な量なので（厳密には標高が高くなるほど標準偏差も値域も大きくなりますが），\n",
        "説明変数にくわえたままにします．\n",
        "\n",
        "説明変数の抽出からやり直します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f3560ef",
      "metadata": {
        "id": "9f3560ef"
      },
      "outputs": [],
      "source": [
        "# 'alt_min', 'alt_max', 'alt_mean', は除外する\n",
        "exp_val = ['alt_std', 'alt_range',\n",
        "    'slope_min', 'slope_max', 'slope_mean', 'slope_std', 'slope_range',\n",
        "    'dis_min', 'dis_max', 'dis_mean', 'dis_std', 'dis_range', 'sti_min',\n",
        "    'sti_max', 'sti_mean', 'sti_std', 'sti_range', 'wi_min', 'wi_max',\n",
        "    'wi_mean', 'wi_std', 'wi_range', 'plc_valley_ratio', 'plc_linear_ratio',\n",
        "    'plc_ridge_ratio', 'prc_convex_ratio', 'prc_linear_ratio', 'prc_concave_ratio']\n",
        "\n",
        "# 説明変数を再度作成する\n",
        "X = aoi_agg_df[exp_val]\n",
        "\n",
        "# 目的変数を再度作成する\n",
        "y = aoi_agg_df['landslide'].astype(int)\n",
        "\n",
        "# データをトレーニングデータと検証データに分ける\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                        test_size=0.25, random_state=123, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31a4f634",
      "metadata": {
        "id": "31a4f634"
      },
      "source": [
        "決定木を作成します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4f7272e",
      "metadata": {
        "id": "d4f7272e"
      },
      "outputs": [],
      "source": [
        "# 土砂災害ありメッシュとなしメッシュの数の違いを考慮する\n",
        "model = DecisionTreeClassifier(class_weight='balanced',\n",
        "                                max_depth=3, random_state=123)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"学習データの正解率\", model.score(X_train, y_train))\n",
        "print(\"検証データの正解率\", model.score(X_test, y_test))\n",
        "\n",
        "print(\"混同行列\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"分類レポート\")\n",
        "print(classification_report(y_test, y_pred,\n",
        "                            target_names=['LS-no', 'LS-yes'] ))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8fad35f",
      "metadata": {
        "id": "d8fad35f"
      },
      "source": [
        "正解率が向上しました．\n",
        "また，混同行列からTP（土砂崩壊ありの正解）も増えたことがわかります．\n",
        "\n",
        "決定木も表示します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9616bb96",
      "metadata": {
        "id": "9616bb96"
      },
      "outputs": [],
      "source": [
        "# 決定木を表示する\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "tree.plot_tree(model, feature_names=exp_val,\n",
        "                class_names=[\"LS-no\", \"LS-yes\"], filled=True, node_ids=True)\n",
        "plt.title(\"Decision Tree\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38b158ea",
      "metadata": {
        "id": "38b158ea"
      },
      "source": [
        "#### 決定木の枝刈り"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d0d71e7",
      "metadata": {
        "id": "2d0d71e7"
      },
      "source": [
        "今までの決定木の形は最上位ノードより下が3段で，葉ノードの数が8個に固定されています．\n",
        "新たねパラメーターを`DecisionTreeClassifier`に加えることで決定木の形を変えることができます．\n",
        "このように決定木の形を変えることを枝刈り（pluning）と呼びます．\n",
        "枝刈りは不要な分岐を抑制してわかりやすい決定木を作るだけでなく，\n",
        "学習データに特化した決定木ができてしまう，いわゆる過学習を抑えることができます．\n",
        "\n",
        "枝刈り（決定木の形状の変更）に関する主なパラメーターには以下の3点があります．\n",
        "これらのパラメーターのことをハイパーパラメーターと呼び，\n",
        "性能のよい決定木を作るために重要な概念となります．\n",
        "\n",
        "* `max_depth`：木の最大深さ\n",
        "* `max_leaf_nodes`：葉の最大数\n",
        "* `min_sample_leaf`：一つの葉を構成する最小のサンプル数\n",
        "\n",
        "ここでは木の最大深さを20（`max_depth=20`），葉の最大数を100（`max_leaf_nodes=100`），\n",
        "一つの葉を構成する最小のサンプル数を1000（`min_sample_leaf=1000`）で決定木を作ってみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3be45326",
      "metadata": {
        "id": "3be45326"
      },
      "outputs": [],
      "source": [
        "# ハイパーパラメータを変更して試してみてください．\n",
        "# 本稿では以下のハイパーパラメーターで最終的な決定木を作ります．\n",
        "# model = DecisionTreeClassifier(class_weight='balanced', max_depth=20,\n",
        "#   max_leaf_nodes=100, min_samples_leaf=1000, random_state=123)\n",
        "\n",
        "model = DecisionTreeClassifier(class_weight='balanced',\n",
        "                                max_depth=20, max_leaf_nodes=100,\n",
        "                                min_samples_leaf=1000, random_state=123)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"学習データの正解率\", model.score(X_train, y_train))\n",
        "print(\"検証データの正解率\", model.score(X_test, y_test))\n",
        "\n",
        "print(\"混同行列\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"分類レポート\")\n",
        "print(classification_report(y_test, y_pred,\n",
        "                            target_names=['LS-no', 'LS-yes'] ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ae24810",
      "metadata": {
        "id": "0ae24810"
      },
      "source": [
        "正解率は落ちていますがprecisionはそれほど落ちていません．\n",
        "混同行列からFN（実際の土砂崩壊はあるが土砂崩壊なしと予測されたサンプル数）が少なく，\n",
        "TP（実際も予測も土砂崩壊あり）が多くなっていることから，土砂崩壊地の取りこぼし（LS-yesのrecall）が少なくなり，\n",
        "決定木の性能が向上しています．\n",
        "\n",
        "このように，ハイパーパラメーターを変えることにより決定木の形が変わり，\n",
        "全体精度や各種評価指標も変化します．\n",
        "機械学習では最もよいハイパーパラメーターを見つけることが重要になってきます．\n",
        "\n",
        "本講習では行いませんが，最適なハイパーパラメーターを探す方法にグリッドサーチがあります．\n",
        "気になる方は調べてみてください．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "147109e3",
      "metadata": {
        "id": "147109e3"
      },
      "source": [
        "決定木も表示してみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a421eb8",
      "metadata": {
        "id": "4a421eb8"
      },
      "outputs": [],
      "source": [
        "# 決定木を表示する\n",
        "plt.figure(figsize=(15, 10))\n",
        "tree.plot_tree(model, feature_names=exp_val, class_names=[\"LS-no\", \"LS-yes\"],\n",
        "                filled=True, node_ids=True)\n",
        "plt.title(\"Decision Tree\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26f65bbb",
      "metadata": {
        "id": "26f65bbb"
      },
      "source": [
        "全体的に決定木が小さくなりました．\n",
        "葉ノードの数は6個で，土砂崩壊ありのハノードも3個になりました．\n",
        "見やすい（解釈しやすい）決定木ができたので，とりあえずこれで完成とします．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47ebcf75",
      "metadata": {
        "id": "47ebcf75"
      },
      "source": [
        "### 決定木による土砂崩壊マップの作成"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51fbe401",
      "metadata": {
        "id": "51fbe401"
      },
      "source": [
        "完成した決定木を用いて土砂崩壊マップを作成しましょう．\n",
        "決定木の作成ではデータを学習用と検証用に分けましたが，\n",
        "マップ作りでは全データに対して決定木を適用し，その結果を表示します．\n",
        "\n",
        "決定木に適用するデータを作成します．\n",
        "標高の絶対値に関する地形量は除外し，全メッシュを含むデータを作成します．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94307fa2",
      "metadata": {
        "id": "94307fa2"
      },
      "outputs": [],
      "source": [
        "# 'alt_min', 'alt_max', 'alt_mean', は除外する\n",
        "exp_val = ['alt_std', 'alt_range',\n",
        "    'slope_min', 'slope_max', 'slope_mean', 'slope_std', 'slope_range',\n",
        "    'dis_min', 'dis_max', 'dis_mean', 'dis_std', 'dis_range', 'sti_min',\n",
        "    'sti_max', 'sti_mean', 'sti_std', 'sti_range', 'wi_min', 'wi_max',\n",
        "    'wi_mean', 'wi_std', 'wi_range', 'plc_valley_ratio', 'plc_linear_ratio',\n",
        "    'plc_ridge_ratio', 'prc_convex_ratio', 'prc_linear_ratio', 'prc_concave_ratio']\n",
        "\n",
        "# 全メッシュの説明変数を作成する\n",
        "all_data = aoi_agg_df[exp_val]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a67c3bb6",
      "metadata": {
        "id": "a67c3bb6"
      },
      "source": [
        "作成した全メッシュのデータに対して決定木を適用し，予測値を求めます．\n",
        "予測値は`all_pred_df`の`ls_pred`列に格納されます．\n",
        "1は土砂崩壊あり，0は土砂崩壊なしです．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "741caf6b",
      "metadata": {
        "id": "741caf6b"
      },
      "outputs": [],
      "source": [
        "# 全メッシュに対して決定木を適用し，\n",
        "# 土砂崩壊の有無を予測する\n",
        "all_pred = model.predict(all_data).tolist()\n",
        "\n",
        "# 予測結果のデータフレームを作成する．\n",
        "all_pred_df = pd.DataFrame(all_pred, columns=['ls_pred'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e2bc511",
      "metadata": {
        "id": "2e2bc511"
      },
      "source": [
        "次に`apply`メソッドを使ってメッシュごとにどのノードに属するか求めます．\n",
        "結果は`all_nodes_df`の`node`列に格納されます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "574f201d",
      "metadata": {
        "id": "574f201d"
      },
      "outputs": [],
      "source": [
        "all_nodes=model.apply(all_data).tolist()\n",
        "all_nodes_df = pd.DataFrame(all_nodes, columns=['node'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac212f84",
      "metadata": {
        "id": "ac212f84"
      },
      "source": [
        "`pd.concat`を使って全メッシュの予測値とノードを集計メッシュ（`aoi_agg_df`）に横結合します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11696b66",
      "metadata": {
        "id": "11696b66"
      },
      "outputs": [],
      "source": [
        "aoi_agg_df = pd.concat([aoi_agg_df, all_pred_df, all_nodes_df], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8032e91",
      "metadata": {
        "id": "b8032e91"
      },
      "source": [
        "`aoi_agg_df`の`landslide`列は実際の土砂崩壊の有無を，`ls_pred`列は土砂崩壊の有無の予測値です．\n",
        "この2列を使ってメッシュが正しく予測されてるかどうかを表すラベルをつけます．\n",
        "実際に土砂崩壊があり（`landslide==1`），予測値でも土砂崩壊がある（`ls_pred==1`）メッシュは真陽性（True Positive）なのでラベル`TP`，\n",
        "実際に土砂崩壊があり（`landslide==1`），予測値では土砂崩壊がない（`ls_pred==0`）メッシュは偽陰性（False Negative）なのでラベル`FN`，\n",
        "実際に土砂崩壊がなく（`landslide==0`），予測値でも土砂崩壊がない（`ls_pred==0`）メッシュは真陰性（True Negative）なのでラベル`TN`，\n",
        "実際に土砂崩壊がなく（`landslide==0`），予測値では土砂崩壊がある（`ls_pred==1`）メッシュは偽陽性（False Negative）なのでラベル`FN`をつけます．\n",
        "このラベルは`aoi_agg_df`の`conmat`列に格納します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6020eba",
      "metadata": {
        "id": "d6020eba"
      },
      "outputs": [],
      "source": [
        "# 実際に土砂崩壊があり（landslide==1），予測値でもある（ls_pred==1）メッシュのconmatをTPに設定\n",
        "aoi_agg_df.loc[(aoi_agg_df['landslide']==1) & (aoi_agg_df['ls_pred']==1),\n",
        "                'conmat'] = 'TP'\n",
        "\n",
        "# 実際に土砂崩壊があり（landslide==1），予測値ではない（ls_pred==0）メッシュのconmatをFNに設定\n",
        "aoi_agg_df.loc[(aoi_agg_df['landslide']==1) & (aoi_agg_df['ls_pred']==0),\n",
        "                'conmat'] = 'FN'\n",
        "\n",
        "# 実際に土砂崩壊がなく（landslide==0），予測値でもない（ls_pred==0）メッシュのconmatをTNに設定\n",
        "aoi_agg_df.loc[(aoi_agg_df['landslide']==0) & (aoi_agg_df['ls_pred']==0),\n",
        "                'conmat'] = 'TN'\n",
        "\n",
        "# 実際に土砂崩壊がなく（landslide==0），予測値ではある（ls_pred==1）メッシュのconmatをFPに設定\n",
        "aoi_agg_df.loc[(aoi_agg_df['landslide']==0) & (aoi_agg_df['ls_pred']==1),\n",
        "                'conmat'] = 'FP'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b79a4b1c",
      "metadata": {
        "id": "b79a4b1c"
      },
      "source": [
        "混同行列のラベルを地図にプロットしてみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "105d2869",
      "metadata": {
        "id": "105d2869"
      },
      "outputs": [],
      "source": [
        "aoi_agg_df.plot(column='conmat', legend=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7c55619",
      "metadata": {
        "id": "e7c55619"
      },
      "source": [
        "FPがかなり多い事に気づいたでしょうか．\n",
        "FPは実際には土砂崩壊なしで予測では土砂崩壊ありとされたメッシュです．\n",
        "全メッシュにおける実際の土砂崩壊の有無と予測による土砂崩壊の有無から混同行列を作ってみます．\n",
        "\n",
        "`confusion_matrix`に実際の土砂災害の有無を格納している列（`aoi_agg_df['landslide']`）と\n",
        "土砂災害の有無の予測値を格納している列（`aoi_agg_df['ls_pred']`）を指定します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "055678db",
      "metadata": {
        "id": "055678db"
      },
      "outputs": [],
      "source": [
        "print(confusion_matrix(aoi_agg_df['landslide'], aoi_agg_df['ls_pred']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d3a6891",
      "metadata": {
        "id": "3d3a6891"
      },
      "source": [
        "|      |      |予測 |  |\n",
        "| ---- | ---- | ---- | ---- |\n",
        "|      |      | なし | あり |\n",
        "| 実際 | なし | 4558 |4158|\n",
        "|  | あり | 507  | 1403    |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "482da091",
      "metadata": {
        "id": "482da091"
      },
      "source": [
        "TP（実際も予測も土砂崩壊あり）が1403サンプルに対してFP（実際にはないが予測ではあり）が4158となっています．\n",
        "これは実際には土砂崩壊なし（4558+4158）の半分近くです．\n",
        "つまり，実際に土砂崩壊がなかったメッシュのうち半分近くは土砂崩壊が「あり」と予測されています．\n",
        "かなりの過推定となっており，機械学習のモデルとしてはあまり良くないように思えます．\n",
        "本来の機械学習はTPとTNが大きくなることが望ましいとされていますが，\n",
        "今回の例でもそうなのでしょうか．\n",
        "\n",
        "今回の決定木の目的は土砂崩壊があるメッシュを推定することです．\n",
        "そのためにDEMから求めた地形量を説明変数，土砂崩壊の実績を目的変数として決定木を作成しました．\n",
        "しかし対象事例とした平成29年7月九州北部豪雨の土砂崩壊は山地に降った大雨によってもたらされています．\n",
        "\n",
        "一般に災害の原因は素因と誘因に分けられます．\n",
        "素因は災害が起きる場の条件（今回の例では土砂崩壊が起きやすい地形），誘因は災害を直接引き起こすトリガーを示しています．\n",
        "今回の分析には素因に関する説明変数のみを用いており，誘因（大雨）に関する変数は入っていません．\n",
        "もしかすると平成29年7月九州北部豪雨の雨に関する変数を加えれば，もっと良い決定木を作ることが出来るかもしれません．\n",
        "しかし雨の分布は地域や事例による差が大きいため，\n",
        "説明変数に雨の情報を加えてしまうと特定の事例の雨（この場合は平成29年7月九州北部豪雨）が\n",
        "降ったときに土砂崩壊を起こす場所を推定する決定木になってしまう恐れがあります．\n",
        "これだと作成した決定木は平成29年7月九州北部豪雨の時にのみ使えるものになってしまい，\n",
        "汎用性のない分類・推定モデルになってしまいます．\n",
        "\n",
        "あえて誘因を説明変数から外すことで，素因（地形）からみて土砂崩壊のポテンシャルが高い地域を取り出せると考えることができます．\n",
        "これを考慮すると，今回作成した決定木のFP（実際には土砂崩壊は起きていないが，予測上は土砂崩壊が起きるとされた場所）に相当するメッシュは，\n",
        "平成29年7月九州北部豪雨ではたまたま土砂崩壊が起きていないが，別の大雨が降った時には土砂崩壊が起こりえる場所と考えることができます．\n",
        "つまりTPとFPのメッシュは「土砂崩壊のポテンシャルが高い場所」と解釈できるのではないでしょうか．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db04f8bc",
      "metadata": {
        "id": "db04f8bc"
      },
      "source": [
        "メッシュがどのノードに属するかを表すマップも表示してみます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19f88f49",
      "metadata": {
        "id": "19f88f49"
      },
      "outputs": [],
      "source": [
        "aoi_agg_df.plot(column='node', categorical=True, legend=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b2dd0c3",
      "metadata": {
        "id": "5b2dd0c3"
      },
      "source": [
        "決定木の葉ノードのノード番号ごとに分類された地図です．\n",
        "同じノードのメッシュは地形が似ていると考えられます．\n",
        "このマップを詳しく見ることにより，なぜ土砂崩壊が起きるのか，もしくは起きないのかを考察することができます．\n",
        "\n",
        "決定木から，ノード1，5，6は土砂崩壊なし，ノード7，9，10は土砂崩壊ありです．\n",
        "今回使用した土砂崩壊値のポリゴンは，崩壊発生域，土砂移動域，土砂堆積域の3つの状態がすべて合わさって\n",
        "土砂崩壊ポリゴンになっています．\n",
        "決定木の土砂崩壊ありの葉ノードにたどり着くまでの分岐条件を詳しく見ていくことで，\n",
        "ある土砂崩壊ありの葉ノードは崩壊発生域，別の崩壊ありの葉ノードは土砂移動域，\n",
        "また別の葉ノードは土砂堆積域を表しているという考察を得られるかもしれません．\n",
        "つまりノードごとに土砂崩壊の状態が異なることがわかるかもしれません．\n",
        "これはマップに表すことで補強することができます．\n",
        "\n",
        "このように土砂崩壊を分類する決定木を作り，混同行列のマップを作ることにより土砂崩壊ポテンシャルの空間分布がわかり，\n",
        "葉ノードのマップを作ることにより土砂崩壊の状態の空間分布がわかってきます．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a00eda00",
      "metadata": {
        "id": "a00eda00"
      },
      "source": [
        "## 結果のエクスポート"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a36f3c0a",
      "metadata": {
        "id": "a36f3c0a"
      },
      "source": [
        "最後に完成した集計データをGISで使うためにエクスポートします．\n",
        "\n",
        "まずはGeoJSONに書き出します．\n",
        "ArcGISでGeoJSONを読むためには，ツールボックスを使ってジオデータベースに変換してから読み込んでください．\n",
        "QGISは直接GeoJSONを扱うことができます．\n",
        "\n",
        "`aoi_agg_df`の`to_file`メソッドでGeoJSONを指定します．\n",
        "実行するとデータフォルダ（Google Colaboratoryを使っている場合はGoogle Driveの`gisday2025`フォルダ）に\n",
        "`aoi_aggregated_data.geojson`というファイル名で保存されます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c3c8aa0",
      "metadata": {
        "id": "9c3c8aa0"
      },
      "outputs": [],
      "source": [
        "aoi_agg_df.to_file(base_dir + \"aoi_aggregated_data.geojson\",\n",
        "                    driver='GeoJSON')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa740016",
      "metadata": {
        "id": "aa740016"
      },
      "source": [
        "シェープファイルにもエクスポートしましょう．\n",
        "こちらも`to_file`メソッドでシェープファイルを指定します．\n",
        "保存先はGeoJSONの場合と同様です．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87328396",
      "metadata": {
        "id": "87328396"
      },
      "outputs": [],
      "source": [
        "aoi_agg_df.to_file(base_dir + \"aoi_aggregated_data.shp\",\n",
        "                    driver='ESRI Shapefile')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cde75103",
      "metadata": {
        "id": "cde75103"
      },
      "source": [
        "## 集計結果をインタラクティブマップ表示する"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "782fbebb",
      "metadata": {
        "id": "782fbebb"
      },
      "source": [
        "最後におまけです．\n",
        "結果をインタラクティブマップに表示してみましょう．\n",
        "データが多いので重たいかもしれません．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beef2745",
      "metadata": {
        "id": "beef2745"
      },
      "outputs": [],
      "source": [
        "mapcenter = [33.416937,130.707376]\n",
        "\n",
        "m = folium.Map(\n",
        "    location=mapcenter,\n",
        "    zoom_start=13\n",
        ")\n",
        "\n",
        "folium.raster_layers.TileLayer(\n",
        "    tiles='https://cyberjapandata.gsi.go.jp/xyz/pale/{z}/{x}/{y}.png',\n",
        "    attr='&copy; <a href=\"https://maps.gsi.go.jp/development/ichiran.html\">\\\n",
        "        地理院タイル</a>',\n",
        "    name='淡色地図'\n",
        ").add_to(m)\n",
        "\n",
        "folium.raster_layers.TileLayer(\n",
        "    tiles='https://cyberjapandata.gsi.go.jp/xyz/hillshademap/{z}/{x}/{y}.png',\n",
        "    attr='&copy; <a href=\"https://maps.gsi.go.jp/development/ichiran.html\">\\\n",
        "        地理院タイル</a>',\n",
        "    name='陰影起伏図'\n",
        ").add_to(m)\n",
        "\n",
        "folium.raster_layers.TileLayer(\n",
        "    tiles='https://cyberjapandata.gsi.go.jp/xyz/20170705typhoon3_0713dol1/{z}/{x}/{y}.png',\n",
        "    attr='&copy; <a href=\"https://maps.gsi.go.jp/development/ichiran.html\">\\\n",
        "        地理院タイル</a>',\n",
        "    name='平成29年7月九州北部豪雨 空中写真（朝倉地区）（2017年7月13日撮影）'\n",
        ").add_to(m)\n",
        "\n",
        "folium.raster_layers.TileLayer(\n",
        "    tiles='https://cyberjapandata.gsi.go.jp/xyz/20170705typhoon3_0713dol2/{z}/{x}/{y}.png',\n",
        "    attr='&copy; <a href=\"https://maps.gsi.go.jp/development/ichiran.html\">\\\n",
        "        地理院タイル</a>',\n",
        "    name='平成29年7月九州北部豪雨 空中写真（東峰地区）（2017年7月13日撮影）'\n",
        ").add_to(m)\n",
        "\n",
        "ls_polygon[ls_polygon['cat']==1].to_crs(epsg=3857).explore(\n",
        "    m=m,\n",
        "    color='red',\n",
        "    name='土砂崩壊地'\n",
        ")\n",
        "\n",
        "aoi_agg_df.to_crs(epsg=3857).explore(\n",
        "    m=m,\n",
        "    column='conmat',\n",
        "    categorical=True,\n",
        "    name='混同行列'\n",
        ")\n",
        "\n",
        "aoi_agg_df.to_crs(epsg=3857).explore(\n",
        "    m=m,\n",
        "    column='node',\n",
        "    categorical=True,\n",
        "    name='ノード'\n",
        ")\n",
        "\n",
        "folium.LayerControl().add_to(m)\n",
        "display(m)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gisday2025",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}